<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>indexing.models.trees.KD_tree API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>indexing.models.trees.KD_tree</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import csv
import heapq
import random
import sys
from collections import Sequence
from itertools import chain, count
from timeit import default_timer as timer

import numpy as np
from sklearn.neighbors import KDTree

sys.path.append(&#39;&#39;)
from src.indexing.utilities.metrics import get_memory_size, mean_squared_error


class KDTreeModel():
    def __init__(self):
        super(KDTreeModel, self).__init__()
        self.name = &#39;KD-Tree&#39;
        self.kdtree = None
        self.page_size = 1

    def train(self, x_train, y_train, x_test, y_test, dim=2):

        #Build kd tree with train data
        data_train = np.hstack((x_train, y_train))
        data_train = data_train.tolist()
        build_time = self.build_kd_tree(data_train)

        # search points kd tree with test data
        y_predict_test = []
        for key in x_test:
            nearest = self.get_nearest(key, dim=2)
            y_predict_test.append(nearest[1][-1])

        y_predict_test = np.array(y_predict_test)
        mse = mean_squared_error(y_test, y_predict_test)

        return mse, build_time

    def predict_range_query(self,
                            query_l,
                            query_u,
                            kd_node=&#39;init&#39;,
                            i=0,
                            out=None):
        xmin = query_l[0]
        xmax = query_u[0]
        ymin = query_l[1]
        ymax = query_u[1]
        self.query_l = query_l
        self.query_u = query_u

        if out == None:
            out = []

        if kd_node == &#39;init&#39;:
            kd_node = self.kdtree

        if kd_node is not None:
            # xmin,ymin,xmax,ymax=area
            xmin, ymin, xmax, ymax
            # acceptance of point within range
            if kd_node[2][0] &gt;= xmin and kd_node[2][0] &lt;= xmax and kd_node[2][
                    1] &gt;= ymin and kd_node[2][1] &lt;= ymax:
                out.append(kd_node[2][2])

            #for traversing left
            if (kd_node[2][i] &gt;= xmin and i == 0) or (kd_node[2][i] &gt;= ymin
                                                      and i == 1):
                self.predict_range_query(self.query_l, self.query_u,
                                         kd_node[0], (i + 1) % 2, out)

            #for traversing right
            if (kd_node[2][i] &lt;= xmax and i == 0) or (kd_node[2][i] &lt;= ymax
                                                      and i == 1):
                self.predict_range_query(self.query_l, self.query_u,
                                         kd_node[1], (i + 1) % 2, out)

        return out

    def depth(self, tree):
        tree_init = tree
        tree = iter(tree)
        try:
            for level in count():
                tree = chain([next(tree)], tree)
                tree = chain.from_iterable(s for s in tree
                                           if isinstance(s, Sequence))
        except StopIteration:
            return level, get_memory_size(tree_init)

    def predict(self, key):
        nearest = self.get_nearest(key, dim=2)
        return nearest[1][-1]

    def build_kd_tree(self, points, dim=2):
        start_time = timer()
        self.kdtree = self.build(points, dim)
        end_time = timer()
        build_time = end_time - start_time
        return build_time

    def build(self, points, dim, i=0):
        if len(points) &gt; 1:
            points.sort(key=lambda x: x[i])
            i = (i + 1) % dim
            half = len(points) &gt;&gt; 1
            return [
                self.build(points[:half], dim, i),
                self.build(points[half + 1:], dim, i), points[half]
            ]
        elif len(points) == 1:
            return [None, None, points[0]]

    def add_point(self, point, dim, kd_node=None, i=0):

        if kd_node is None:
            kd_node = self.kdtree
        if kd_node is not None:
            dx = kd_node[2][i] - point[i]
            i = (i + 1) % dim  # i is to alternate bw x and y
            for j, c in (
                (0, dx &gt;= 0), (1, dx &lt; 0)
            ):  # j is for left and right addition  and c is to check where to add
                if c and kd_node[j] is None:
                    kd_node[j] = [None, None, point]
                elif c:
                    self.add_point(point, dim, kd_node[j], i)

    def predict_knn_query_find(self,
                               point,
                               k,
                               dim=2,
                               kd_node=&#39;init&#39;,
                               return_distances=True,
                               i=0,
                               heap=None):

        if kd_node == &#39;init&#39;:
            kd_node = self.kdtree

        is_root = not heap
        if is_root:
            heap = []
        if kd_node is not None:
            dist = self.dist_sq_dim(point, kd_node[2], dim)
            dx = kd_node[2][i] - point[i]
            if len(heap) &lt; k:
                heapq.heappush(heap, (-dist, kd_node[2]))
            elif dist &lt; -heap[0][0]:
                heapq.heappushpop(heap, (-dist, kd_node[2]))
            i = (i + 1) % dim
            # Goes into the left branch, and then the right branch if needed
            for b in [dx &lt; 0] + [dx &gt;= 0] * (
                    dx * dx &lt; -heap[0][0]
            ):  # dx*dx is r&#39; and decide whether to check other branch or not.
                self.predict_knn_query_find(point, k, dim, kd_node[b],
                                            return_distances, i, heap)
        if is_root:
            neighbors = sorted((-h[0], h[1]) for h in heap)
            return neighbors if return_distances else [n[1] for n in neighbors]

    def predict_knn_query(self,
                          point,
                          k,
                          dim=2,
                          kd_node=&#39;init&#39;,
                          return_distances=True,
                          i=0,
                          heap=None):

        y_pred = self.predict_knn_query_find(point, k, dim, kd_node,
                                             return_distances, i, heap)
        y_pred = np.array(y_pred)
        # yhat=np.vstack(y_pred[:,1])[:,2]
        yhat = np.vstack(y_pred[:, 0])
        return np.sqrt(yhat)

    def get_nearest(self,
                    point,
                    dim,
                    kd_node=&#39;init&#39;,
                    return_distances=True,
                    i=0,
                    nearest=None):

        if kd_node == &#39;init&#39;:
            kd_node = self.kdtree

        if kd_node is not None:
            dist = self.dist_sq_dim(point, kd_node[2], dim)
            dx = kd_node[2][i] - point[i]
            if not nearest:
                nearest = [dist, kd_node[2]]
            elif dist &lt; nearest[0]:
                nearest[0], nearest[1] = dist, kd_node[2]
            i = (i + 1) % dim
            # Goes into the left branch, and then the right branch if needed
            for b in [dx &lt; 0] + [dx &gt;= 0] * (dx * dx &lt; nearest[0]):
                self.get_nearest(point, dim, kd_node[b], return_distances, i,
                                 nearest)
        return nearest if return_distances else nearest[1]

    def rand_point(self, dim):
        return [random.uniform(-1, 1) for d in range(dim)]

    def dist_sq(self, a, b, dim):
        return sum((a[i] - b[i])**2 for i in range(dim))

    def dist_sq_dim(self, a, b, dim):
        return self.dist_sq(a, b, dim)

    def get_storage(self):

        return self.kdtree


&#34;&#34;&#34;
Below is all the testing code
&#34;&#34;&#34;
if __name__ == &#34;__main__&#34;:

    # filename=sys.argv[1]
    # dim = sys.argv[2]
    m = 100
    # for i in range(0,4):
    #     m = m*10
    #     filename = &#39;data/2d_lognormal_lognormal_&#39; + str(m) + &#39;.csv&#39;
    #     print(filename)
    #     dim = 2

    # ***** Reading data points from csv ******
    filename = &#39;data/2d_lognormal_lognormal_&#39; + str(19000000) + &#39;.csv&#39;
    dim = 2
    points = []
    with open(filename, &#39;r&#39;) as csvfile:
        points_reader = csv.reader(csvfile, delimiter=&#39;,&#39;, quotechar=&#39;|&#39;)
        next(points_reader)
        for point in points_reader:
            points.append(list(np.float_(point)))
    # points = [[11,12],[3,4],[4,5],[6,7],[8,9]]
    test = [[3, 1]]
    result = []

    kdtree = KDTreeModel()
    bt = kdtree.build_kd_tree(points, dim)

    levels, storage = kdtree.depth(kdtree.kdtree)

    print(levels, &#34;levels of KDTree&#34;)

    print(storage, &#34;Storage of KDTree&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="indexing.models.trees.KD_tree.KDTreeModel"><code class="flex name class">
<span>class <span class="ident">KDTreeModel</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class KDTreeModel():
    def __init__(self):
        super(KDTreeModel, self).__init__()
        self.name = &#39;KD-Tree&#39;
        self.kdtree = None
        self.page_size = 1

    def train(self, x_train, y_train, x_test, y_test, dim=2):

        #Build kd tree with train data
        data_train = np.hstack((x_train, y_train))
        data_train = data_train.tolist()
        build_time = self.build_kd_tree(data_train)

        # search points kd tree with test data
        y_predict_test = []
        for key in x_test:
            nearest = self.get_nearest(key, dim=2)
            y_predict_test.append(nearest[1][-1])

        y_predict_test = np.array(y_predict_test)
        mse = mean_squared_error(y_test, y_predict_test)

        return mse, build_time

    def predict_range_query(self,
                            query_l,
                            query_u,
                            kd_node=&#39;init&#39;,
                            i=0,
                            out=None):
        xmin = query_l[0]
        xmax = query_u[0]
        ymin = query_l[1]
        ymax = query_u[1]
        self.query_l = query_l
        self.query_u = query_u

        if out == None:
            out = []

        if kd_node == &#39;init&#39;:
            kd_node = self.kdtree

        if kd_node is not None:
            # xmin,ymin,xmax,ymax=area
            xmin, ymin, xmax, ymax
            # acceptance of point within range
            if kd_node[2][0] &gt;= xmin and kd_node[2][0] &lt;= xmax and kd_node[2][
                    1] &gt;= ymin and kd_node[2][1] &lt;= ymax:
                out.append(kd_node[2][2])

            #for traversing left
            if (kd_node[2][i] &gt;= xmin and i == 0) or (kd_node[2][i] &gt;= ymin
                                                      and i == 1):
                self.predict_range_query(self.query_l, self.query_u,
                                         kd_node[0], (i + 1) % 2, out)

            #for traversing right
            if (kd_node[2][i] &lt;= xmax and i == 0) or (kd_node[2][i] &lt;= ymax
                                                      and i == 1):
                self.predict_range_query(self.query_l, self.query_u,
                                         kd_node[1], (i + 1) % 2, out)

        return out

    def depth(self, tree):
        tree_init = tree
        tree = iter(tree)
        try:
            for level in count():
                tree = chain([next(tree)], tree)
                tree = chain.from_iterable(s for s in tree
                                           if isinstance(s, Sequence))
        except StopIteration:
            return level, get_memory_size(tree_init)

    def predict(self, key):
        nearest = self.get_nearest(key, dim=2)
        return nearest[1][-1]

    def build_kd_tree(self, points, dim=2):
        start_time = timer()
        self.kdtree = self.build(points, dim)
        end_time = timer()
        build_time = end_time - start_time
        return build_time

    def build(self, points, dim, i=0):
        if len(points) &gt; 1:
            points.sort(key=lambda x: x[i])
            i = (i + 1) % dim
            half = len(points) &gt;&gt; 1
            return [
                self.build(points[:half], dim, i),
                self.build(points[half + 1:], dim, i), points[half]
            ]
        elif len(points) == 1:
            return [None, None, points[0]]

    def add_point(self, point, dim, kd_node=None, i=0):

        if kd_node is None:
            kd_node = self.kdtree
        if kd_node is not None:
            dx = kd_node[2][i] - point[i]
            i = (i + 1) % dim  # i is to alternate bw x and y
            for j, c in (
                (0, dx &gt;= 0), (1, dx &lt; 0)
            ):  # j is for left and right addition  and c is to check where to add
                if c and kd_node[j] is None:
                    kd_node[j] = [None, None, point]
                elif c:
                    self.add_point(point, dim, kd_node[j], i)

    def predict_knn_query_find(self,
                               point,
                               k,
                               dim=2,
                               kd_node=&#39;init&#39;,
                               return_distances=True,
                               i=0,
                               heap=None):

        if kd_node == &#39;init&#39;:
            kd_node = self.kdtree

        is_root = not heap
        if is_root:
            heap = []
        if kd_node is not None:
            dist = self.dist_sq_dim(point, kd_node[2], dim)
            dx = kd_node[2][i] - point[i]
            if len(heap) &lt; k:
                heapq.heappush(heap, (-dist, kd_node[2]))
            elif dist &lt; -heap[0][0]:
                heapq.heappushpop(heap, (-dist, kd_node[2]))
            i = (i + 1) % dim
            # Goes into the left branch, and then the right branch if needed
            for b in [dx &lt; 0] + [dx &gt;= 0] * (
                    dx * dx &lt; -heap[0][0]
            ):  # dx*dx is r&#39; and decide whether to check other branch or not.
                self.predict_knn_query_find(point, k, dim, kd_node[b],
                                            return_distances, i, heap)
        if is_root:
            neighbors = sorted((-h[0], h[1]) for h in heap)
            return neighbors if return_distances else [n[1] for n in neighbors]

    def predict_knn_query(self,
                          point,
                          k,
                          dim=2,
                          kd_node=&#39;init&#39;,
                          return_distances=True,
                          i=0,
                          heap=None):

        y_pred = self.predict_knn_query_find(point, k, dim, kd_node,
                                             return_distances, i, heap)
        y_pred = np.array(y_pred)
        # yhat=np.vstack(y_pred[:,1])[:,2]
        yhat = np.vstack(y_pred[:, 0])
        return np.sqrt(yhat)

    def get_nearest(self,
                    point,
                    dim,
                    kd_node=&#39;init&#39;,
                    return_distances=True,
                    i=0,
                    nearest=None):

        if kd_node == &#39;init&#39;:
            kd_node = self.kdtree

        if kd_node is not None:
            dist = self.dist_sq_dim(point, kd_node[2], dim)
            dx = kd_node[2][i] - point[i]
            if not nearest:
                nearest = [dist, kd_node[2]]
            elif dist &lt; nearest[0]:
                nearest[0], nearest[1] = dist, kd_node[2]
            i = (i + 1) % dim
            # Goes into the left branch, and then the right branch if needed
            for b in [dx &lt; 0] + [dx &gt;= 0] * (dx * dx &lt; nearest[0]):
                self.get_nearest(point, dim, kd_node[b], return_distances, i,
                                 nearest)
        return nearest if return_distances else nearest[1]

    def rand_point(self, dim):
        return [random.uniform(-1, 1) for d in range(dim)]

    def dist_sq(self, a, b, dim):
        return sum((a[i] - b[i])**2 for i in range(dim))

    def dist_sq_dim(self, a, b, dim):
        return self.dist_sq(a, b, dim)

    def get_storage(self):

        return self.kdtree</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.add_point"><code class="name flex">
<span>def <span class="ident">add_point</span></span>(<span>self, point, dim, kd_node=None, i=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_point(self, point, dim, kd_node=None, i=0):

    if kd_node is None:
        kd_node = self.kdtree
    if kd_node is not None:
        dx = kd_node[2][i] - point[i]
        i = (i + 1) % dim  # i is to alternate bw x and y
        for j, c in (
            (0, dx &gt;= 0), (1, dx &lt; 0)
        ):  # j is for left and right addition  and c is to check where to add
            if c and kd_node[j] is None:
                kd_node[j] = [None, None, point]
            elif c:
                self.add_point(point, dim, kd_node[j], i)</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, points, dim, i=0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(self, points, dim, i=0):
    if len(points) &gt; 1:
        points.sort(key=lambda x: x[i])
        i = (i + 1) % dim
        half = len(points) &gt;&gt; 1
        return [
            self.build(points[:half], dim, i),
            self.build(points[half + 1:], dim, i), points[half]
        ]
    elif len(points) == 1:
        return [None, None, points[0]]</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.build_kd_tree"><code class="name flex">
<span>def <span class="ident">build_kd_tree</span></span>(<span>self, points, dim=2)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_kd_tree(self, points, dim=2):
    start_time = timer()
    self.kdtree = self.build(points, dim)
    end_time = timer()
    build_time = end_time - start_time
    return build_time</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.depth"><code class="name flex">
<span>def <span class="ident">depth</span></span>(<span>self, tree)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def depth(self, tree):
    tree_init = tree
    tree = iter(tree)
    try:
        for level in count():
            tree = chain([next(tree)], tree)
            tree = chain.from_iterable(s for s in tree
                                       if isinstance(s, Sequence))
    except StopIteration:
        return level, get_memory_size(tree_init)</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.dist_sq"><code class="name flex">
<span>def <span class="ident">dist_sq</span></span>(<span>self, a, b, dim)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dist_sq(self, a, b, dim):
    return sum((a[i] - b[i])**2 for i in range(dim))</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.dist_sq_dim"><code class="name flex">
<span>def <span class="ident">dist_sq_dim</span></span>(<span>self, a, b, dim)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dist_sq_dim(self, a, b, dim):
    return self.dist_sq(a, b, dim)</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.get_nearest"><code class="name flex">
<span>def <span class="ident">get_nearest</span></span>(<span>self, point, dim, kd_node='init', return_distances=True, i=0, nearest=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_nearest(self,
                point,
                dim,
                kd_node=&#39;init&#39;,
                return_distances=True,
                i=0,
                nearest=None):

    if kd_node == &#39;init&#39;:
        kd_node = self.kdtree

    if kd_node is not None:
        dist = self.dist_sq_dim(point, kd_node[2], dim)
        dx = kd_node[2][i] - point[i]
        if not nearest:
            nearest = [dist, kd_node[2]]
        elif dist &lt; nearest[0]:
            nearest[0], nearest[1] = dist, kd_node[2]
        i = (i + 1) % dim
        # Goes into the left branch, and then the right branch if needed
        for b in [dx &lt; 0] + [dx &gt;= 0] * (dx * dx &lt; nearest[0]):
            self.get_nearest(point, dim, kd_node[b], return_distances, i,
                             nearest)
    return nearest if return_distances else nearest[1]</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.get_storage"><code class="name flex">
<span>def <span class="ident">get_storage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_storage(self):

    return self.kdtree</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, key)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, key):
    nearest = self.get_nearest(key, dim=2)
    return nearest[1][-1]</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.predict_knn_query"><code class="name flex">
<span>def <span class="ident">predict_knn_query</span></span>(<span>self, point, k, dim=2, kd_node='init', return_distances=True, i=0, heap=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_knn_query(self,
                      point,
                      k,
                      dim=2,
                      kd_node=&#39;init&#39;,
                      return_distances=True,
                      i=0,
                      heap=None):

    y_pred = self.predict_knn_query_find(point, k, dim, kd_node,
                                         return_distances, i, heap)
    y_pred = np.array(y_pred)
    # yhat=np.vstack(y_pred[:,1])[:,2]
    yhat = np.vstack(y_pred[:, 0])
    return np.sqrt(yhat)</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.predict_knn_query_find"><code class="name flex">
<span>def <span class="ident">predict_knn_query_find</span></span>(<span>self, point, k, dim=2, kd_node='init', return_distances=True, i=0, heap=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_knn_query_find(self,
                           point,
                           k,
                           dim=2,
                           kd_node=&#39;init&#39;,
                           return_distances=True,
                           i=0,
                           heap=None):

    if kd_node == &#39;init&#39;:
        kd_node = self.kdtree

    is_root = not heap
    if is_root:
        heap = []
    if kd_node is not None:
        dist = self.dist_sq_dim(point, kd_node[2], dim)
        dx = kd_node[2][i] - point[i]
        if len(heap) &lt; k:
            heapq.heappush(heap, (-dist, kd_node[2]))
        elif dist &lt; -heap[0][0]:
            heapq.heappushpop(heap, (-dist, kd_node[2]))
        i = (i + 1) % dim
        # Goes into the left branch, and then the right branch if needed
        for b in [dx &lt; 0] + [dx &gt;= 0] * (
                dx * dx &lt; -heap[0][0]
        ):  # dx*dx is r&#39; and decide whether to check other branch or not.
            self.predict_knn_query_find(point, k, dim, kd_node[b],
                                        return_distances, i, heap)
    if is_root:
        neighbors = sorted((-h[0], h[1]) for h in heap)
        return neighbors if return_distances else [n[1] for n in neighbors]</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.predict_range_query"><code class="name flex">
<span>def <span class="ident">predict_range_query</span></span>(<span>self, query_l, query_u, kd_node='init', i=0, out=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_range_query(self,
                        query_l,
                        query_u,
                        kd_node=&#39;init&#39;,
                        i=0,
                        out=None):
    xmin = query_l[0]
    xmax = query_u[0]
    ymin = query_l[1]
    ymax = query_u[1]
    self.query_l = query_l
    self.query_u = query_u

    if out == None:
        out = []

    if kd_node == &#39;init&#39;:
        kd_node = self.kdtree

    if kd_node is not None:
        # xmin,ymin,xmax,ymax=area
        xmin, ymin, xmax, ymax
        # acceptance of point within range
        if kd_node[2][0] &gt;= xmin and kd_node[2][0] &lt;= xmax and kd_node[2][
                1] &gt;= ymin and kd_node[2][1] &lt;= ymax:
            out.append(kd_node[2][2])

        #for traversing left
        if (kd_node[2][i] &gt;= xmin and i == 0) or (kd_node[2][i] &gt;= ymin
                                                  and i == 1):
            self.predict_range_query(self.query_l, self.query_u,
                                     kd_node[0], (i + 1) % 2, out)

        #for traversing right
        if (kd_node[2][i] &lt;= xmax and i == 0) or (kd_node[2][i] &lt;= ymax
                                                  and i == 1):
            self.predict_range_query(self.query_l, self.query_u,
                                     kd_node[1], (i + 1) % 2, out)

    return out</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.rand_point"><code class="name flex">
<span>def <span class="ident">rand_point</span></span>(<span>self, dim)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rand_point(self, dim):
    return [random.uniform(-1, 1) for d in range(dim)]</code></pre>
</details>
</dd>
<dt id="indexing.models.trees.KD_tree.KDTreeModel.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, x_train, y_train, x_test, y_test, dim=2)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, x_train, y_train, x_test, y_test, dim=2):

    #Build kd tree with train data
    data_train = np.hstack((x_train, y_train))
    data_train = data_train.tolist()
    build_time = self.build_kd_tree(data_train)

    # search points kd tree with test data
    y_predict_test = []
    for key in x_test:
        nearest = self.get_nearest(key, dim=2)
        y_predict_test.append(nearest[1][-1])

    y_predict_test = np.array(y_predict_test)
    mse = mean_squared_error(y_test, y_predict_test)

    return mse, build_time</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="indexing.models.trees" href="index.html">indexing.models.trees</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="indexing.models.trees.KD_tree.KDTreeModel" href="#indexing.models.trees.KD_tree.KDTreeModel">KDTreeModel</a></code></h4>
<ul class="">
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.add_point" href="#indexing.models.trees.KD_tree.KDTreeModel.add_point">add_point</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.build" href="#indexing.models.trees.KD_tree.KDTreeModel.build">build</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.build_kd_tree" href="#indexing.models.trees.KD_tree.KDTreeModel.build_kd_tree">build_kd_tree</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.depth" href="#indexing.models.trees.KD_tree.KDTreeModel.depth">depth</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.dist_sq" href="#indexing.models.trees.KD_tree.KDTreeModel.dist_sq">dist_sq</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.dist_sq_dim" href="#indexing.models.trees.KD_tree.KDTreeModel.dist_sq_dim">dist_sq_dim</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.get_nearest" href="#indexing.models.trees.KD_tree.KDTreeModel.get_nearest">get_nearest</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.get_storage" href="#indexing.models.trees.KD_tree.KDTreeModel.get_storage">get_storage</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.predict" href="#indexing.models.trees.KD_tree.KDTreeModel.predict">predict</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.predict_knn_query" href="#indexing.models.trees.KD_tree.KDTreeModel.predict_knn_query">predict_knn_query</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.predict_knn_query_find" href="#indexing.models.trees.KD_tree.KDTreeModel.predict_knn_query_find">predict_knn_query_find</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.predict_range_query" href="#indexing.models.trees.KD_tree.KDTreeModel.predict_range_query">predict_range_query</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.rand_point" href="#indexing.models.trees.KD_tree.KDTreeModel.rand_point">rand_point</a></code></li>
<li><code><a title="indexing.models.trees.KD_tree.KDTreeModel.train" href="#indexing.models.trees.KD_tree.KDTreeModel.train">train</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>