

\section{Introduction}

%TODO: there should be some graph to demonstrate the last-mile problem.

Spatial data and query processing have become ubiquitous due to proliferation of location-based services such as digital mapping, location-based social networking,
and geo-targeted advertising. Motivated by the performance benefits of learned indices
for one-dimensional data, this section explores the application of learned index for spatial data. The main motivation is to use machine learning models through several steps, to generate a learned index for spatial data. 

\section{Motivation}
In the last section, we described a recursive model index (RMI) that consists of a
number of machine learning models staged into a hierarchy to enable synthesis of specialised index structures, termed learned indexes. Provided with a search key x, RMI predicts the position of x's data with some error bound, by learning the cumulative distribution function (CDF) over the key search space. However, the idea of RMI is not applicable in the context of spatial data as spatial data invalidates the assumption required by RMI that the data is sorted by key and that any imprecision can be easily corrected by a localised search. Although it is possible to learn multi-dimensional CDFs, such CDFs will result in searching local regions qualified on one dimension but not all dimensions.

For example, consider the joint cumulative function of two random variables X and Y defined as $F_{XY}(x, y)=P(X\leq x, Y\leq y)$.

The joint CDF satisfies the following properties:

\begin{itemize}
  \item  {$F_X(x)=F_{XY}(x,\infty)$, for any x (marginal CDF of X)}
  \item  {$F_Y(y)=F_{XY}(\infty,y)$, for any y (marginal CDF of Y)}
  \item  {if $X$ and $Y$ are independent, then $F_{XY}(x,y)=F_X(x)F_Y(y)$}
\end{itemize}

\textcolor{blue} {Need to find a solid argument to explain why learning multi dimensional CDFs will result in  searching local regions qualified on one dimension. }
LISA solves this problem by partitioning search space into a series of grid cells based on the data distribution and building a partially monotonic function according to the borders of cells to map the data from $\mathbb{R}^d$ into $\mathbb{R}$.

\section{Definitions}

This section presents the definition

\begin{enumerate}
	\item \textbf{Key}. A key k is a unique identifier for a data record with $k = (x_{0}, x_{1}) \in \mathbb{R}^{2}$. 
    %\textcolor{blue} {Need to check how to write d-1 in subscript }
    
	\item \textbf{Cell}. A grid cell is a rectangle whose lower and upper corners are points $(l_{0},l_{1}) and  (u_{0},u_{1})$, i.e.,  cell = $(l_{0},u_{0}) \times [l_{1},u_{1})$
	
	\item \textbf{Mapping Function}. A mapping function M is a partially monotonic function on the domain $\mathbb{R}^{2}$ to the non-negative range,i.e $M:[0,X_{0}]\times[0,X_{1}]\to [0,+\infty)$ such that $M(x_{0},x_{1}) \leq M(y_{0},y_{1})$ when $x_{0} \leq y_{0}$ and $x_{1} \leq y_{1} $
    
\end{enumerate}
% $f:\mathbb{R}\to\mathbb{R}, x\to y$ where $x$ is the input index and $y$ is the corresponding page block
\section{Baseline Method}  

We can extend the learned index method for range queries on spatial data by using a mapping function. This baseline method works as follows. We first sort all keys according to their mapped values and divide the mapped values into equal number of cells. If a point
(x,y)â€™s mapped value is larger than those of the keys stored
in the first i cells, i.e. $M(x,y) > \sup \bigcup\limits_{j=0}^{i-1} M(C_{j})$, we store (x,y) in cell i. Subsequently, for a query rectangle
qr = $[l_{0},u_{0}) \times [l_{1},u_{1})$, we only need to predict $i_{1}$ and $i_{2}$, the indices of $(l_{0}, l_{1})$ and $(u_{0},u_{1})$, respectively, scan the keys in $i_{2}$ - $i_{1}$ + 1 cells, and those keys that fall in the query rectangle qr . 


\begin{enumerate}
	\item \textbf{Input} : Key in the initial data set
    \item \textbf{Output}: Define M monotonic mapping function
    \item calculate the mapped values of all keys in key space using M
    \item Sort keys according to their mapped values. 
    \item Store the sorted keys in a number of pages.
\end{enumerate}


%\begin{enumerate}
%	\item \textbf{Input} : Key in the initial data set
%    \item \textbf{Output}: M monotonic mapping function
%    \item for i=0 to 1, do
%    \item Partition Key Space along $x_{i}$ and generate $\Theta_{i}$
%    \item Generate all grid cells based on all $\Theta_{i}$
%    \item Generate mapping function M
%    \item calculate the mapped values of all keys in I using M
%    \item Sort keys belonging to a cell according to their mapped values. 
%\end{enumerate}



